{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1pJh1JvM-dI"
   },
   "source": [
    "# Generative Search System (RAG) Case Study Notebook\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Insurance policy documents contain vast amounts of information, and manually searching for relevant details is time-consuming and inefficient. Traditional keyword-based search systems often fail to provide contextually relevant answers.\n",
    "\n",
    "**Mr.HelpMate AI** aims to address these challenges by leveraging **AI-powered Retrieval-Augmented Generation (RAG)** to create an intelligent, conversational search assistant capable of:\n",
    "\n",
    "- Accurately extracting relevant policy details  \n",
    "- Understanding natural language queries  \n",
    "- Generating concise and contextually relevant answers  \n",
    "\n",
    "This project will implement and experiment with various strategies to optimize retrieval and generation quality, ultimately improving user experience in navigating policy documents.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overall System Design & Innovation\n",
    "\n",
    "This project implements a **Retrieval-Augmented Generation (RAG)** system to create a robust generative search engine capable of effectively answering questions from a single, long **Group Member Life Insurance Policy** document.\n",
    "\n",
    "The system is designed around a **three-layer architecture**:  \n",
    "**Embedding**, **Search**, and **Generation**.Innovation is focused on optimizing performance and output quality within each layer through strategic model and algorithm choices, including mandatory components like a **Cache** and **Re-ranking block**.\n",
    "\n",
    "## Search System's Architecture, Workflow, and Implementation\n",
    "\n",
    "### 1. Embedding Layer (Indexing)\n",
    "- Extracts policy text robustly (handling tables) using pdfplumber, applies a Custom Fixed-Size Character Splitting strategy for optimal chunks, and converts them into vectors using the efficient `all-MiniLM-L6-v2` model from `sentence-transformers`.\n",
    "\n",
    "### 2. Search Layer (Retrieval):\n",
    "- Uses a persistent ChromaDB vector store. It integrates a Cache Mechanism for speed and a mandatory Cross-Encoder Re-ranker (using `sentence-transformers`) to ensure only the most relevant chunks are retrieved.\n",
    "\n",
    "### 3. Generation Layer (Synthesis)\n",
    "- An Exhaustive Prompt is engineered to guide the OpenAI LLM (e.g., `gpt-3.5-turbo`) to provide precise, contextual, and, most importantly, cited answers directly from the policy excerpts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkgrxpMDPPKq"
   },
   "source": [
    "## 2.  Setup and Imports\n",
    "\n",
    "This cell installs and imports all necessary libraries for the **RAG pipeline**.  \n",
    "We're using **open-source models** to enable a simple, local setup without relying on proprietary APIs or cloud services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlXWxSrxP3AP",
    "outputId": "c1883880-90b2-41b0-eeea-f93efd813684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content/drive/MyDrive/Colab Notebooks/GenAI/02_Helpmate_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/GenAI/02_Helpmate_project\")\n",
    "print(\"Current directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HghqEgzCPWen",
    "outputId": "3906dd69-ae7f-41f4-f030-12577b25d52d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Libraries imported and configurations set.\n"
     ]
    }
   ],
   "source": [
    "# SETUP AND IMPORTS\n",
    "\n",
    "!pip install -qqq pdfplumber tiktoken openai chromadb sentence-transformers\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pdfplumber\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# It's recommended to use environment variables or a key management service.\n",
    "# For demonstration, we are taking key from a file stored locally.\n",
    "\n",
    " # Load API key\n",
    "with open(\"OpenAI_API_Key.txt\", \"r\") as f:\n",
    "    OPENAI_API_KEY = f.read().strip()\n",
    "\n",
    "# --- System Configuration Constants ---\n",
    "\n",
    "PDF_PATH = \"Principal-Sample-Life-Insurance-Policy.pdf\"\n",
    "CHROMA_DB_PATH = \"./rag_case_study_db\"\n",
    "COLLECTION_NAME = \"insurance_policy_chunks\"\n",
    "CACHE_COLLECTION_NAME = \"query_cache\"\n",
    "CACHE_THRESHOLD = 0.05       # Distance threshold for cache hit (lower = stricter match)\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "RERANKER_MODEL_NAME = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "GENERATION_MODEL_NAME = \"gpt-3.5-turbo\" # Using OpenAI for generation layer\n",
    "TOP_K_CHUNKS = 10            # Number of chunks to retrieve initially from ChromaDB\n",
    "TOP_N_RERANKED = 3           # Number of top chunks passed to the LLM (for Generation)\n",
    "\n",
    "# Initialize Clients\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"Setup complete. Libraries imported and configurations set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57gVb2B2U3tO"
   },
   "source": [
    "## 3. Embedding Layer: Processing and Optimal Chunking\n",
    "\n",
    "This section implements the effectiveness in processing the text data and the application of an effective and optimal chunking strategy.\n",
    "\n",
    "### 3.1 PDF Text Extraction (Robust, Handles Tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpNINpodPQ65",
    "outputId": "177b913e-bf7c-43db-d7c5-ac68ef7f8a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content from 'Principal-Sample-Life-Insurance-Policy.pdf'...\n",
      "Extracted content from 64 pages.\n"
     ]
    }
   ],
   "source": [
    "# PDF TEXT EXTRACTION\n",
    "\n",
    "def extract_text_from_pdf_robust(pdf_path: str) -> List[Dict]:\n",
    "    #Extracts text from PDF, ensuring tables are captured correctly using pdfplumber.\n",
    "    full_text = []\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"ERROR: File not found at path: {pdf_path}. Please upload your policy document.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Extracting content from '{pdf_path}'...\")\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for p, page in enumerate(pdf.pages):\n",
    "            page_no = f\"Page {p+1}\"\n",
    "\n",
    "            # Find and process tables\n",
    "            tables = page.find_tables()\n",
    "            # Convert table data to JSON string for better LLM context\n",
    "            tables_content = [{'text': json.dumps(t.extract()), 'top': t.bbox[1]} for t in tables]\n",
    "            table_bboxes = [i.bbox for i in tables]\n",
    "\n",
    "            # Helper function to check if a word is inside a table area\n",
    "            def is_in_table(word, bboxes):\n",
    "                l = word['x0'], word['top'], word['x1'], word['bottom']\n",
    "                for r in bboxes:\n",
    "                    if l[0] > r[0] and l[1] > r[1] and l[2] < r[2] and l[3] < r[3]:\n",
    "                        return True\n",
    "                return False\n",
    "\n",
    "            # Extract words that are NOT part of a table\n",
    "            non_table_words = [\n",
    "                {'text': word['text'], 'top': word['top']}\n",
    "                for word in page.extract_words()\n",
    "                if not is_in_table(word, table_bboxes)\n",
    "            ]\n",
    "\n",
    "            # Combine all content (text and tables) and sort by vertical position to maintain flow\n",
    "            page_objects = non_table_words + tables_content\n",
    "            page_objects.sort(key=itemgetter('top'))\n",
    "\n",
    "            # Reconstruct the page text\n",
    "            page_content = \" \".join([obj['text'] for obj in page_objects])\n",
    "\n",
    "            full_text.append({\n",
    "                'Page_No.': page_no,\n",
    "                'Page_Text': page_content.strip()\n",
    "            })\n",
    "\n",
    "    print(f\"Extracted content from {len(pdf.pages)} pages.\")\n",
    "    return full_text\n",
    "\n",
    "# Execute extraction\n",
    "extracted_data = extract_text_from_pdf_robust(PDF_PATH)\n",
    "if extracted_data:\n",
    "    text_df = pd.DataFrame(extracted_data)\n",
    "else:\n",
    "    text_df = None\n",
    "    print(\"Cannot proceed: No data extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ikRmGNfZdtwe",
    "outputId": "7ffc4522-65b5-4bb5-a83c-efe5ca1134c6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"text_df\",\n  \"rows\": 64,\n  \"fields\": [\n    {\n      \"column\": \"Page_No.\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"Page 53\",\n          \"Page 59\",\n          \"Page 1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Page_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62,\n        \"samples\": [\n          \"(1) only one Accelerated Benefit payment will be made during the Member's lifetime; and (2) the amount requested must be at least $5,000; and (3) in no event will payment exceed the lesser of: - 75% of the Member Life Insurance benefit in force on the date of the request; or - $250,000. The Accelerated Benefit payment will be made in a lump sum. d. Effect on Member Life Insurance Benefits If an Accelerated Benefit is paid, the Member Life Insurance Benefit otherwise payable upon the Member's death will be reduced by any Accelerated Benefit payment. e. Premium Waiver Period A premium waiver period will be established on the date The Principal pays an Accelerated Benefit to a Member. This period will end on the earlier of the Member's death or the date two years after the date of the Accelerated Benefit. During a premium waiver period: (1) there will be no Member Life and Member Accidental Death and Dismemberment Insurance and Dependent Life Insurance premium charge for the Member; and (2) Member Life Insurance will not be terminated if the Member ceases Active Work because of his or her Terminal Illness. This policy has been updated effective January 1, 2014 PART IV - BENEFITS GC 6013 Section A - Member Life Insurance, Page 7\",\n          \"a. willful self-injury or self-destruction, while sane or insane; or b. disease, medical or surgical treatment of disease, or complications following the surgical treatment of disease; or c. voluntary participation in an assault, felony, criminal activity, insurrection, or riot; or d. participation in flying, ballooning, parachuting, parasailing, bungee jumping or other aeronautic activities, except as a passenger on a commercial aircraft or as a passenger in a Policyholder-owned or leased aircraft on company business; or e. duty as a member of a military organization; or f. war or act of war; or g. the use of alcohol if, at the time of the injury, the Member's alcohol concentration exceeds the legal limit allowed by the jurisdiction where the injury occurs; or h. the operation by the Member of a motor vehicle or motor boat if, at the time of the injury, the Member's alcohol concentration exceeds the legal limit allowed by the jurisdiction where the injury occurs; or i. the use of any drug, narcotic, or hallucinogen not prescribed for the Member by a licensed Physician; or j. injury arising from or during employment for wage or profit. This policy has been updated effective January 1, 2014 PART IV - BENEFITS GC 6015 Section B - Member Accidental Death and Dismemberment Insurance, Page 6\",\n          \"DOROTHEA GLAUSE S655 RHODE ISLAND JOHN DOE 01/01/2014 711 HIGH STREET GEORGE RI 02903 GROUP POLICY FOR: RHODE ISLAND JOHN DOE ALL MEMBERS Group Member Life Insurance Print Date: 07/16/2014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "text_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2a9e6c60-7fc4-40d2-b451-dffb9c3f65bd\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page_No.</th>\n",
       "      <th>Page_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Page 1</td>\n",
       "      <td>DOROTHEA GLAUSE S655 RHODE ISLAND JOHN DOE 01/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Page 2</td>\n",
       "      <td>This page left blank intentionally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Page 3</td>\n",
       "      <td>POLICY RIDER GROUP INSURANCE POLICY NO: S655 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Page 4</td>\n",
       "      <td>This page left blank intentionally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Page 5</td>\n",
       "      <td>PRINCIPAL LIFE INSURANCE COMPANY (called The P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a9e6c60-7fc4-40d2-b451-dffb9c3f65bd')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2a9e6c60-7fc4-40d2-b451-dffb9c3f65bd button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2a9e6c60-7fc4-40d2-b451-dffb9c3f65bd');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-e58fd3e7-9701-45a9-b14c-613de6b87ba5\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e58fd3e7-9701-45a9-b14c-613de6b87ba5')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-e58fd3e7-9701-45a9-b14c-613de6b87ba5 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  Page_No.                                          Page_Text\n",
       "0   Page 1  DOROTHEA GLAUSE S655 RHODE ISLAND JOHN DOE 01/...\n",
       "1   Page 2                 This page left blank intentionally\n",
       "2   Page 3  POLICY RIDER GROUP INSURANCE POLICY NO: S655 C...\n",
       "3   Page 4                 This page left blank intentionally\n",
       "4   Page 5  PRINCIPAL LIFE INSURANCE COMPANY (called The P..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's view the data\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR2NknNhVPxN"
   },
   "source": [
    "### 3.2 Applying Optimal Chunking Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dsRxHihVQX_",
    "outputId": "56e7dccd-2d02-489e-8f56-00717c612a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Custom Fixed-Size Character Splitter (Size: 512, Overlap: 128)...\n",
      "Original pages: 64, Total chunks created: 278\n"
     ]
    }
   ],
   "source": [
    "# OPTIMAL CHUNKING (Custom Fixed-Size Character Splitting)\n",
    "\n",
    "def fixed_size_chunker(text: str, chunk_size: int, overlap: int) -> List[str]:\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    # Use character length as the metric\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        # Calculate the next start position with overlap\n",
    "        if len(chunk) < chunk_size:\n",
    "            break\n",
    "\n",
    "        start += (chunk_size - overlap)\n",
    "        if start < 0:\n",
    "             start = 0 # Should only happen if overlap > chunk_size, but acts as safeguard\n",
    "\n",
    "    return chunks\n",
    "\n",
    "if text_df is not None and not text_df.empty:\n",
    "    CHUNK_SIZE = 512\n",
    "    CHUNK_OVERLAP = 128\n",
    "\n",
    "    print(f\"Applying Custom Fixed-Size Character Splitter (Size: {CHUNK_SIZE}, Overlap: {CHUNK_OVERLAP})...\")\n",
    "\n",
    "    chunks_data = []\n",
    "\n",
    "    for index, row in text_df.iterrows():\n",
    "        page_content = row['Page_Text']\n",
    "        metadata = {'Page_No.': row['Page_No.'].replace('.', '')}\n",
    "\n",
    "        # Split the document text using the custom function\n",
    "        chunks = fixed_size_chunker(page_content, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP)\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_metadata = metadata.copy()\n",
    "            chunk_metadata['Chunk_No.'] = i + 1\n",
    "\n",
    "            chunks_data.append({\n",
    "                'chunk_text': chunk,\n",
    "                'metadata': chunk_metadata\n",
    "            })\n",
    "\n",
    "    chunks_df = pd.DataFrame(chunks_data)\n",
    "    print(f\"Original pages: {len(text_df)}, Total chunks created: {len(chunks_df)}\")\n",
    "else:\n",
    "    chunks_df = None\n",
    "    print(\"Skipping chunking as no data was extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFjiJF3JehEl",
    "outputId": "184ab1e8-3516-48b8-8a65-c17837d637a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metadata             | Chunk_Text_Snippet                                                                                      |\n",
      "|:---------------------|:--------------------------------------------------------------------------------------------------------|\n",
      "| Page Page 1, Chunk 1 | DOROTHEA GLAUSE S655 RHODE ISLAND JOHN DOE 01/01/2014 711 HIGH STREET GEORGE RI 02903 GROUP POLICY F... |\n",
      "| Page Page 2, Chunk 1 | This page left blank intentionally...                                                                   |\n",
      "| Page Page 3, Chunk 1 | POLICY RIDER GROUP INSURANCE POLICY NO: S655 COVERAGE: Life EMPLOYER: RHODE ISLAND JOHN DOE Effectiv... |\n",
      "| Page Page 3, Chunk 2 | rvices or any other value added service for the employees of that employer group. In addition, The P... |\n",
      "| Page Page 3, Chunk 3 | hese goods, services and/or third party provider discounts, the third party service providers are li... |\n"
     ]
    }
   ],
   "source": [
    "# Let's view data after CHUNKING (First 5 Chunks) ---\n",
    "chunks_sample = chunks_df.head(5).copy()\n",
    "chunks_sample['Chunk_Text_Snippet'] = chunks_sample['chunk_text'].str[:100].str.replace('\\n', ' ') + \"...\"\n",
    "chunks_sample['Metadata'] = chunks_sample['metadata'].apply(lambda x: f\"Page {x['Page_No.']}, Chunk {x['Chunk_No.']}\")\n",
    "print(chunks_sample[['Metadata', 'Chunk_Text_Snippet']].to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwp7z0rsVpu2"
   },
   "source": [
    "### 3.3 Embedding and ChromaDB Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rfb3J67fVq52",
    "outputId": "bd439446-7d1f-445d-f0c6-3d9f463855fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Embedding Model: all-MiniLM-L6-v2\n",
      "ChromaDB already contains 278 chunks. Skipping load.\n"
     ]
    }
   ],
   "source": [
    "# EMBEDDING AND CHROMADB STORAGE\n",
    "\n",
    "if chunks_df is not None and not chunks_df.empty:\n",
    "    # 1. Appropriate Choice of Embedding Model\n",
    "    embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    print(f\"Using Embedding Model: {EMBEDDING_MODEL_NAME}\")\n",
    "\n",
    "    # 2. Initialize Persistent ChromaDB Client and Collections\n",
    "    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "\n",
    "    # Main Collection for Policy Chunks\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    # Cache Collection (for mandatory cache implementation)\n",
    "    cache_collection = client.get_or_create_collection(\n",
    "        name=CACHE_COLLECTION_NAME,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    # 3. Add chunks to the collection (only if not already loaded)\n",
    "    ids = [f\"chunk_{i}\" for i in range(len(chunks_df))]\n",
    "    documents = chunks_df['chunk_text'].tolist()\n",
    "    metadatas = chunks_df['metadata'].tolist()\n",
    "\n",
    "    if collection.count() != len(documents):\n",
    "        collection.upsert(documents=documents, metadatas=metadatas, ids=ids)\n",
    "\n",
    "        collection.add(\n",
    "            documents=documents,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )\n",
    "        print(f\"ChromaDB loaded with {collection.count()} chunks into '{COLLECTION_NAME}'.\")\n",
    "    else:\n",
    "        print(f\"ChromaDB already contains {collection.count()} chunks. Skipping load.\")\n",
    "else:\n",
    "    print(\"Skipping ChromaDB setup as chunking failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMyDc869e46D",
    "outputId": "8966f104-724c-457f-ee34-b2b8bc614271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in 'insurance_policy_chunks': 278\n",
      "This confirms the chunk text has been converted to vectors and stored in ChromaDB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': ['chunk_0',\n",
       "  'chunk_1',\n",
       "  'chunk_2',\n",
       "  'chunk_3',\n",
       "  'chunk_4',\n",
       "  'chunk_5',\n",
       "  'chunk_6',\n",
       "  'chunk_7',\n",
       "  'chunk_8',\n",
       "  'chunk_9'],\n",
       " 'embeddings': array([[-0.02592193,  0.04777753,  0.05585773, ..., -0.04932659,\n",
       "         -0.05851149,  0.02355198],\n",
       "        [ 0.02911896,  0.06057408,  0.04641531, ...,  0.05954009,\n",
       "         -0.02838372,  0.00531935],\n",
       "        [-0.06910008,  0.04697426,  0.00010474, ..., -0.04099483,\n",
       "          0.02056715, -0.00662788],\n",
       "        ...,\n",
       "        [-0.05875206,  0.06800337,  0.06347963, ..., -0.03584532,\n",
       "         -0.00298454, -0.02332482],\n",
       "        [-0.0812709 ,  0.0445028 ,  0.05686409, ..., -0.10154654,\n",
       "         -0.00629883,  0.04746101],\n",
       "        [-0.02865543,  0.03401795,  0.01736274, ..., -0.0199494 ,\n",
       "          0.05256363, -0.06476747]]),\n",
       " 'documents': ['DOROTHEA GLAUSE S655 RHODE ISLAND JOHN DOE 01/01/2014 711 HIGH STREET GEORGE RI 02903 GROUP POLICY FOR: RHODE ISLAND JOHN DOE ALL MEMBERS Group Member Life Insurance Print Date: 07/16/2014',\n",
       "  'This page left blank intentionally',\n",
       "  'POLICY RIDER GROUP INSURANCE POLICY NO: S655 COVERAGE: Life EMPLOYER: RHODE ISLAND JOHN DOE Effective on the later of the Date of Issue of this Group Policy or March 1, 2005, the following will apply to your Policy: From time to time The Principal may offer or provide certain employer groups who apply for coverage with The Principal a Financial Services Hotline and Grief Support Services or any other value added service for the employees of that employer group. In addition, The Principal may arrange for thi',\n",
       "  'rvices or any other value added service for the employees of that employer group. In addition, The Principal may arrange for third party service providers (i.e., optometrists, health clubs), to provide discounted goods and services to those employer groups who apply for coverage with The Principal or who become insureds/enrollees of The Principal. While The Principal has arranged these goods, services and/or third party provider discounts, the third party service providers are liable to the applicants/insur',\n",
       "  'hese goods, services and/or third party provider discounts, the third party service providers are liable to the applicants/insureds/enrollees for the provision of such goods and/or services. The Principal is not responsible for the provision of such goods and/or services nor is it liable for the failure of the provision of the same. Further, The Principal is not liable to the applicants/insureds/enrollees for the negligent provision of such goods and/or services by the third party service providers. EXCEPT ',\n",
       "  'cants/insureds/enrollees for the negligent provision of such goods and/or services by the third party service providers. EXCEPT AS SPECIFICALLY DESCRIBED IN THIS RIDER, ALL OTHER BENEFITS AND PROVISIONS WILL BE AS DESCRIBED IN THE GROUP POLICY. PRINCIPAL LIFE INSURANCE COMPANY DES MOINES, IOWA 50392-0001 GC 806 VAL',\n",
       "  'This page left blank intentionally',\n",
       "  \"PRINCIPAL LIFE INSURANCE COMPANY (called The Principal in this Group Policy) Des Moines, Iowa 50392-0002 This group insurance policy is issued to: RHODE ISLAND JOHN DOE (called the Policyholder in this Group Policy) The Date of Issue is November 1, 2007. In return for the Policyholder's application and payment of all premiums when due, The Principal agrees to provide: MEMBER LIFE INSURANCE MEMBER ACCIDENTAL DEATH AND DISMEMBERMENT INSURANCE DEPENDENT LIFE INSURANCE subject to the terms and conditions descri\",\n",
       "  'NSURANCE MEMBER ACCIDENTAL DEATH AND DISMEMBERMENT INSURANCE DEPENDENT LIFE INSURANCE subject to the terms and conditions described in this Group Policy. GROUP POLICY NO. GL S655 RENEWABLE TERM - NON-PARTICIPATING CONTRACT STATE OF ISSUE: RHODE ISLAND This policy has been updated effective January 1, 2014 GC 6000 TITLE PAGE',\n",
       "  'TABLE OF CONTENTS PART I - DEFINITIONS PART II - POLICY ADMINISTRATION Section A – Contract Entire Contract Article 1 Policy Changes Article 2 Policyholder Eligibility Requirements Article 3 Policy Incontestability Article 4 Individual Incontestability Article 5 Information to be Furnished Article 6 Certificates Article 7 Assignments Article 8 Dependent Rights Article 9 Policy Interpretation Article 10 Electronic Transactions Article 11 Section B – Premium Payment Responsibility; Due Dates; Grace Period Art'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'Page_No.': 'Page 1', 'Chunk_No.': 1},\n",
       "  {'Page_No.': 'Page 2', 'Chunk_No.': 1},\n",
       "  {'Chunk_No.': 1, 'Page_No.': 'Page 3'},\n",
       "  {'Page_No.': 'Page 3', 'Chunk_No.': 2},\n",
       "  {'Page_No.': 'Page 3', 'Chunk_No.': 3},\n",
       "  {'Page_No.': 'Page 3', 'Chunk_No.': 4},\n",
       "  {'Page_No.': 'Page 4', 'Chunk_No.': 1},\n",
       "  {'Page_No.': 'Page 5', 'Chunk_No.': 1},\n",
       "  {'Page_No.': 'Page 5', 'Chunk_No.': 2},\n",
       "  {'Page_No.': 'Page 6', 'Chunk_No.': 1}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's view data after EMBEDDING/STORAGE ---\n",
    "print(f\"Total documents in '{COLLECTION_NAME}': {collection.count()}\")\n",
    "print(\"This confirms the chunk text has been converted to vectors and stored in ChromaDB.\")\n",
    "collection.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JkcBmVahrDD",
    "outputId": "c33c0a54-35c2-4fbf-b10c-e0dc46bc15a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['what_is_the_official_definition_of_a__dependent__under_this_group_member_life_insurance_policy_',\n",
       "  'according_to_the_policy__what_is_the_effective_date_for_a_change_in_scheduled_benefit_amount_that_requires_proof_of_good_health_',\n",
       "  'what_is_the_procedure_and_time_limit_for_a_claimant_to_appeal_a_claim_denial_decision_',\n",
       "  'what_is_the_proof_of_adl_disability_or_total_disability_',\n",
       "  'what_is_condition_of_death_while_not_wearing_seat_belt_',\n",
       "  'what_event_marks_the_effective_date_for_the_policy_rider_described_in_the_document_',\n",
       "  'according_to_the_policy__what_is_the_earliest_and_latest_time_limit_for_a_claimant_to_start_legal_action_to_recover_benefits_',\n",
       "  'what_if_i_fail_to_pay_premium_'],\n",
       " 'embeddings': array([[-0.07271644,  0.03535411, -0.03075045, ...,  0.005109  ,\n",
       "          0.08578993, -0.01217845],\n",
       "        [-0.03723065,  0.10137826,  0.03557216, ..., -0.01043161,\n",
       "          0.01724429, -0.00549376],\n",
       "        [-0.03440192,  0.10575985, -0.00418625, ...,  0.00963795,\n",
       "          0.02529203,  0.08859247],\n",
       "        ...,\n",
       "        [ 0.00763934,  0.10678018,  0.03681344, ...,  0.04898207,\n",
       "         -0.00828404, -0.00759731],\n",
       "        [-0.09963816,  0.06397684, -0.020731  , ...,  0.01562146,\n",
       "          0.01252062,  0.04741199],\n",
       "        [-0.04851045,  0.04386197,  0.03594507, ..., -0.13402984,\n",
       "          0.01202716, -0.01232496]]),\n",
       " 'documents': [\"What is the official definition of a 'Dependent' under this Group Member Life Insurance Policy?\",\n",
       "  'According to the policy, what is the effective date for a change in Scheduled Benefit amount that requires Proof of Good Health?',\n",
       "  'What is the procedure and time limit for a claimant to appeal a claim denial decision?',\n",
       "  'what is the Proof of ADL Disability or Total Disability?',\n",
       "  'what is condition of death while not wearing Seat Belt?',\n",
       "  'What event marks the effective date for the POLICY RIDER described in the document?',\n",
       "  'According to the policy, what is the earliest and latest time limit for a claimant to start legal action to recover benefits?',\n",
       "  'what if i fail to pay premium?'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'type': 'query'},\n",
       "  {'type': 'query'},\n",
       "  {'type': 'query'},\n",
       "  {'type': 'query'},\n",
       "  {'type': 'query'},\n",
       "  {'type': 'query'},\n",
       "  {'type': 'query'},\n",
       "  {'type': 'query'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_collection.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QDpC5PxXp-7"
   },
   "source": [
    "## 4. Search Layer: Cache and Re-ranking\n",
    "\n",
    "This section implements the quality of the search results by adding the mandatory cache and the re-ranker using the allowed sentence-transformers library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4Ij_MEIXq1T",
    "outputId": "1f2d9442-65f9-4fc2-d497-7b5b094cb079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up Mandatory Re-ranker: cross-encoder/ms-marco-MiniLM-L-6-v2...\n",
      "Re-ranker model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# CACHE, SEARCH, AND RE-RANKING FUNCTIONS\n",
    "\n",
    "def query_with_cache(query_text: str, k_chunks: int = TOP_K_CHUNKS):\n",
    "    print(f\"-> Querying DB with k={k_chunks}...\")\n",
    "\n",
    "    # 1. Mandatory Cache Check\n",
    "    try:\n",
    "        cache_results = cache_collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=1,\n",
    "            include=['distances']\n",
    "        )\n",
    "\n",
    "        # Check for cache hit based on distance threshold (Selection and implementation of cache)\n",
    "        if (cache_results and cache_results['distances'] and cache_results['distances'][0]\n",
    "            and cache_results['distances'][0][0] <= CACHE_THRESHOLD):\n",
    "\n",
    "            print(f\"CACHE HIT. Query is highly similar to a past query. Distance: {cache_results['distances'][0][0]:.4f}\")\n",
    "            # Note: In a full RAG implementation, we would retrieve the *cached answer* here.\n",
    "        else:\n",
    "            print(\"Cache Miss/Irrelevant. Proceeding with search.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Cache check error (non-fatal): {e}\")\n",
    "\n",
    "    # 2. Query Main Collection\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=k_chunks,\n",
    "        include=['documents', 'metadatas', 'distances']\n",
    "    )\n",
    "\n",
    "    # 3. Cache Update (Store the current query's embedding for future checks)\n",
    "    cache_collection.add(\n",
    "        documents=[query_text],\n",
    "        metadatas=[{'type': 'query'}],\n",
    "        # Generate a unique ID for the query, constrained by ChromaDB ID length\n",
    "        ids=[re.sub(r'[^a-z0-9]', '_', query_text.lower())[:128]]\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# Mandatory Re-ranking Model Setup (Selection and implementation of a re-ranker)\n",
    "print(f\"\\nSetting up Mandatory Re-ranker: {RERANKER_MODEL_NAME}...\")\n",
    "# Use CrossEncoder directly from the allowed sentence_transformers library\n",
    "reranker_model = CrossEncoder(RERANKER_MODEL_NAME)\n",
    "print(\"Re-ranker model loaded successfully.\")\n",
    "\n",
    "def rerank_results(query: str, results: Dict[str, Any], top_n: int = TOP_N_RERANKED) -> List[Dict]:\n",
    "\n",
    "    initial_chunks = results['documents'][0]\n",
    "    initial_metadatas = results['metadatas'][0]\n",
    "\n",
    "    # 1. Create pairs of (query, chunk_text) for the cross-encoder\n",
    "    cross_inputs = [[query, chunk] for chunk in initial_chunks]\n",
    "\n",
    "    # 2. Get the relevance scores\n",
    "    scores = reranker_model.predict(cross_inputs)\n",
    "\n",
    "    # 3. Combine and sort by score\n",
    "    scored_chunks = []\n",
    "    for chunk, metadata, score in zip(initial_chunks, initial_metadatas, scores.tolist()):\n",
    "        scored_chunks.append({\n",
    "            'chunk_text': chunk,\n",
    "            'metadata': metadata,\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "    # Sort by relevance score (highest score is most relevant)\n",
    "    reranked_chunks = sorted(scored_chunks, key=itemgetter('score'), reverse=True)\n",
    "\n",
    "    # 4. Return the top N results for the LLM\n",
    "    return reranked_chunks[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQpgQBhJYDjG"
   },
   "source": [
    "## 5. Generative Layer: Prompt Quality and Final Answers\n",
    "\n",
    "This section implements the mandatory quality of the prompt and final answers, using the openai client structure, and focusing on hallucination mitigation and traceability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "a2V9CsSImNfl"
   },
   "outputs": [],
   "source": [
    "# GENERATION LAYER (Prompt Design and LIVE OpenAI LLM Call)\n",
    "\n",
    "\n",
    "def generate_response(query: str, retrieved_chunks: List[Dict]) -> str:\n",
    "    #Creates the RAG prompt with context and instructions, then generates the final answer using OpenAI.\n",
    "\n",
    "    # 1. Format the context with clear sources\n",
    "    context_list = []\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        # Create a citation tag for the context\n",
    "        citation_source = f\"Page {chunk['metadata']['Page_No.']}, Chunk {chunk['metadata']['Chunk_No.']}\"\n",
    "        context_list.append(f\"[{citation_source}]: {chunk['chunk_text']}\")\n",
    "\n",
    "    context_text = \"\\n---\\n\".join(context_list)\n",
    "\n",
    "    # 2. Design the Exhaustive Prompt\n",
    "    system_prompt = f\"\"\"\n",
    "    ROLE: You are an expert generative search system specializing in Group Member Life Insurance policy documents.\n",
    "    TASK: Answer the user's question accurately and concisely, based *only* on the provided context.\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    1. **Strictly adhere to the context.** Do not use external knowledge. If the answer is not in the context, state: \"The required information is not available in the provided policy excerpts.\"\n",
    "    2. Answer the question directly and professionally.\n",
    "    3. **MANDATORY CITATION:** After the final answer, include a \"Citations:\" section. For every fact you use, cite the corresponding source in the context.\n",
    "    4. **Citation Format:** Use the exact format `` for each citation.\n",
    "\n",
    "    POLICY EXCERPTS (CONTEXT):\n",
    "    {context_text}\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"USER QUESTION:\\n{query}\"\n",
    "\n",
    "    # 3. Generate the final response (LIVE OpenAI API CALL)\n",
    "    print(f\"   Calling LIVE OpenAI LLM ({GENERATION_MODEL_NAME})...\")\n",
    "\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=GENERATION_MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.0 # Set low for factual retrieval\n",
    "        )\n",
    "        final_response = response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        final_response = f\"**LLM GENERATION ERROR:** The API call failed. Please verify your OpenAI API Key in Cell 1 and ensure you have enough credits. Error details: {e}\"\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cqz7a9xYbew"
   },
   "source": [
    "## 6. Query Search and Performance Evaluation\n",
    "\n",
    "This cell executes the full RAG pipeline against your three self-designed queries and prints the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUr2_5ELYf72",
    "outputId": "6428dfe1-4c46-4ff1-9b8e-761645017bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING RAG SYSTEM AGAINST 3 SELF-DESIGNED QUERIES (LIVE API CALL)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Query 1: List the three specific conditions that will cause a Member's Life Insurance to terminate.? ---\n",
      "-> Querying DB with k=10...\n",
      "Cache Miss/Irrelevant. Proceeding with search.\n",
      "\n",
      "--- SAMPLE DATA: INITIAL CHROMA SEARCH (Top 3 of K=10, Ranked by Distance) ---\n",
      "|   Rank (by Distance) |   Distance (Lower is Better) | Chunk_Text_Snippet                                                                                      |\n",
      "|---------------------:|-----------------------------:|:--------------------------------------------------------------------------------------------------------|\n",
      "|                    1 |                       0.3183 | n A Member will qualify for individual purchase if insurance under this Group Policy terminates and:... |\n",
      "|                    2 |                       0.3185 | Section C - Individual Terminations Article 1 - Member Life Insurance A Member's insurance under thi... |\n",
      "|                    3 |                       0.3308 | insured for Dependent Life Insurance for at least five years, such insurance terminates because the ... |\n",
      "\n",
      "[SEARCH LAYER - TOP 3 RERANKED CHUNKS (Ranked by Relevance Score)]\n",
      "|   Rank | Page_Source   |   Relevance_Score | Chunk_Text                                                                                                                                                                              |\n",
      "|-------:|:--------------|------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|      1 | Page 42       |            2.8675 | n A Member will qualify for individual purchase if insurance under this Group Policy terminates and: (1) the Member's total Life Insurance, or any portion of it, terminates because... |\n",
      "|      2 | Page 36       |            2.8641 | A Member's insurance under this Group Policy for a Dependent will terminate on the earliest of: a. the date his or her Member Life Insurance ceases; or b. the date Dependent Life I... |\n",
      "|      3 | Page 35       |            2.7025 | Section C - Individual Terminations Article 1 - Member Life Insurance A Member's insurance under this Group Policy will terminate on the earliest of: a. the date this Group Policy ... |\n",
      "   Calling LIVE OpenAI LLM (gpt-3.5-turbo)...\n",
      "\n",
      "[GENERATION LAYER - FINAL LLM ANSWER]\n",
      "QUERY: List the three specific conditions that will cause a Member's Life Insurance to terminate.?\n",
      "======================================================================\n",
      "The three specific conditions that will cause a Member's Life Insurance to terminate are:\n",
      "1. The date the Member ceases to be in a class for which Member Life Insurance is provided.\n",
      "2. The date the Member ceases to be a Member as defined in PART I.\n",
      "3. The date the last premium is paid for the Member's insurance.\n",
      "\n",
      "Citations:\n",
      "- [Page 35, Chunk 1]\n",
      "\n",
      "\n",
      "--- Query 2: What event marks the effective date for the POLICY RIDER described in the document? ---\n",
      "-> Querying DB with k=10...\n",
      "CACHE HIT. Query is highly similar to a past query. Distance: -0.0000\n",
      "\n",
      "--- SAMPLE DATA: INITIAL CHROMA SEARCH (Top 3 of K=10, Ranked by Distance) ---\n",
      "|   Rank (by Distance) |   Distance (Lower is Better) | Chunk_Text_Snippet                                                                                      |\n",
      "|---------------------:|-----------------------------:|:--------------------------------------------------------------------------------------------------------|\n",
      "|                    1 |                       0.4127 | by The Principal. g. Effective Date for Benefit Changes Due to Change by Policy Amendment (1) A chan... |\n",
      "|                    2 |                       0.4369 | has been updated effective January 1, 2014 PART III - INDIVIDUAL REQUIREMENTS AND RIGHTS GC 6007 Sec... |\n",
      "|                    3 |                       0.4404 | ept as described below. This policy has been updated effective January 1, 2014 PART III - INDIVIDUAL... |\n",
      "\n",
      "[SEARCH LAYER - TOP 3 RERANKED CHUNKS (Ranked by Relevance Score)]\n",
      "|   Rank | Page_Source   |   Relevance_Score | Chunk_Text                                                                                                                                                                              |\n",
      "|-------:|:--------------|------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|      1 | Page 32       |            0.6522 | ept as described below. This policy has been updated effective January 1, 2014 PART III - INDIVIDUAL REQUIREMENTS AND RIGHTS GC 6007 Section B - Effective Dates, Page 5...             |\n",
      "|      2 | Page 30       |           -0.1612 | by The Principal. g. Effective Date for Benefit Changes Due to Change by Policy Amendment (1) A change in the Member's Scheduled Benefit amount because of a change in the Schedule ... |\n",
      "|      3 | Page 20       |           -1.2025 | on any premium due date, if the initial premium rate has then been in force 24 months or more and if Written notice is given to the Policyholder at least 31 days before the date of... |\n",
      "   Calling LIVE OpenAI LLM (gpt-3.5-turbo)...\n",
      "\n",
      "[GENERATION LAYER - FINAL LLM ANSWER]\n",
      "QUERY: What event marks the effective date for the POLICY RIDER described in the document?\n",
      "======================================================================\n",
      "The effective date for a POLICY RIDER described in the document is the date of change, as stated in the policy excerpts. \n",
      "\n",
      "Citations:\n",
      "- [Page 30, Chunk 6]: \"A change in the Member's Scheduled Benefit amount because of a change in the Schedule of Insurance by amendment to this Group Policy for which Proof of Good Health is not required will be effective on the date of change.\"\n",
      "\n",
      "\n",
      "--- Query 3: According to the policy, what is the earliest and latest time limit for a claimant to start legal action to recover benefits? ---\n",
      "-> Querying DB with k=10...\n",
      "CACHE HIT. Query is highly similar to a past query. Distance: -0.0000\n",
      "\n",
      "--- SAMPLE DATA: INITIAL CHROMA SEARCH (Top 3 of K=10, Ranked by Distance) ---\n",
      "|   Rank (by Distance) |   Distance (Lower is Better) | Chunk_Text_Snippet                                                                                      |\n",
      "|---------------------:|-----------------------------:|:--------------------------------------------------------------------------------------------------------|\n",
      "|                    1 |                       0.3084 | appeal procedures have been exhausted. Further, no legal action may be started later than three year... |\n",
      "|                    2 |                       0.3865 | . The Principal is permitted two 30-day extensions for processing an incomplete claim. Written notif... |\n",
      "|                    3 |                       0.3932 | yment as described in PART IV, Section A, Article 7 and less the amount for which the Member becomes... |\n",
      "\n",
      "[SEARCH LAYER - TOP 3 RERANKED CHUNKS (Ranked by Relevance Score)]\n",
      "|   Rank | Page_Source   |   Relevance_Score | Chunk_Text                                                                                                                                                                              |\n",
      "|-------:|:--------------|------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|      1 | Page 62       |            5.1162 | appeal procedures have been exhausted. Further, no legal action may be started later than three years after that proof is required to be filed. Article 8 - Time Limits Any time lim... |\n",
      "|      2 | Page 61       |            0.9804 | . The Principal is permitted two 30-day extensions for processing an incomplete claim. Written notification will be sent to the claimant regarding the extension. In actual practice... |\n",
      "|      3 | Page 61       |            0.2129 | Section D - Claim Procedures Article 1 - Notice of Claim Written notice must be sent to The Principal by or for a Member or Dependent who wishes to file claim for benefits under th... |\n",
      "   Calling LIVE OpenAI LLM (gpt-3.5-turbo)...\n",
      "\n",
      "[GENERATION LAYER - FINAL LLM ANSWER]\n",
      "QUERY: According to the policy, what is the earliest and latest time limit for a claimant to start legal action to recover benefits?\n",
      "======================================================================\n",
      "The latest time limit for a claimant to start legal action to recover benefits is three years after the proof of loss is required to be filed. The earliest time limit is not specified in the provided policy excerpts.\n",
      "\n",
      "Citations:\n",
      "- `[Page 62, Chunk 5]`\n",
      "\n",
      "================================================================================\n",
      "EXECUTION COMPLETE.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# EXECUTION\n",
    "\n",
    "# 1. Design Test Queries\n",
    "queries = {\n",
    "    \"Query 1\": \"List the three specific conditions that will cause a Member's Life Insurance to terminate.?\",\n",
    "    \"Query 2\": \"What event marks the effective date for the POLICY RIDER described in the document?\",\n",
    "    \"Query 3\": \"According to the policy, what is the earliest and latest time limit for a claimant to start legal action to recover benefits?\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING RAG SYSTEM AGAINST 3 SELF-DESIGNED QUERIES (LIVE API CALL)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize clients here to ensure they are available\n",
    "try:\n",
    "    if 'client' not in locals():\n",
    "        print(\"Note: Initializing ChromaDB client for execution...\")\n",
    "        client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "        collection = client.get_or_create_collection(name=COLLECTION_NAME, embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL_NAME))\n",
    "        cache_collection = client.get_or_create_collection(name=CACHE_COLLECTION_NAME, embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBEDDING_MODEL_NAME))\n",
    "except Exception as e:\n",
    "    print(f\"Warning: ChromaDB client initialization failed. {e}. Please ensure previous cells ran successfully.\")\n",
    "\n",
    "\n",
    "for query_name, query_text in queries.items():\n",
    "    print(f\"\\n\\n--- {query_name}: {query_text} ---\")\n",
    "\n",
    "    # 1. SEARCH LAYER: Query (with Cache check)\n",
    "    initial_results = query_with_cache(query_text, k_chunks=TOP_K_CHUNKS)\n",
    "\n",
    "    # --- SAMPLE DATA AFTER INITIAL SEARCH (Pre-Re-ranking) ---\n",
    "    print(\"\\n--- SAMPLE DATA: INITIAL CHROMA SEARCH (Top 3 of K=10, Ranked by Distance) ---\")\n",
    "    pre_rerank_data = pd.DataFrame({\n",
    "        'Rank (by Distance)': range(1, 4),\n",
    "        'Distance (Lower is Better)': [f\"{d:.4f}\" for d in initial_results['distances'][0][:3]],\n",
    "        'Chunk_Text_Snippet': [t[:100].replace('\\n', ' ') + \"...\" for t in initial_results['documents'][0][:3]]\n",
    "    })\n",
    "    print(pre_rerank_data.to_markdown(index=False))\n",
    "    # ----------------------------------------------------------------------------------\n",
    "\n",
    "    # 2. SEARCH LAYER: Mandatory Re-ranking\n",
    "    top_3_reranked = rerank_results(query_text, initial_results, top_n=TOP_N_RERANKED)\n",
    "\n",
    "    # --- 1: SEARCH LAYER OUTPUT (Top 3 Reranked Chunks) ---\n",
    "    print(\"\\n[SEARCH LAYER - TOP 3 RERANKED CHUNKS (Ranked by Relevance Score)]\")\n",
    "    top_3_chunks_for_ss = pd.DataFrame([\n",
    "        {'Rank': i+1,\n",
    "         'Page_Source': chunk['metadata']['Page_No.'],\n",
    "         'Relevance_Score': f\"{chunk['score']:.4f}\",\n",
    "         'Chunk_Text': chunk['chunk_text'][:180] + \"...\"}\n",
    "        for i, chunk in enumerate(top_3_reranked)\n",
    "    ])\n",
    "\n",
    "    # Table output\n",
    "    print(top_3_chunks_for_ss.to_markdown(index=False))\n",
    "\n",
    "    # 3. GENERATION LAYER: Generate Final Answer (LIVE CALL)\n",
    "    final_answer = generate_response(query_text, top_3_reranked)\n",
    "\n",
    "    # --- 2: GENERATION LAYER OUTPUT (Final LLM Answer) ---\n",
    "    print(\"\\n[GENERATION LAYER - FINAL LLM ANSWER]\")\n",
    "    print(f\"QUERY: {query_text}\\n{'='*70}\")\n",
    "    print(final_answer)\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTION COMPLETE.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJMvUHJpZPIO"
   },
   "source": [
    "## 7. Documentation: Design Choices & Challenges\n",
    "\n",
    "## Project Goals & Data Source\n",
    "* **Goal:** Build a robust Generative Search System (RAG) for the **Group Member Life Insurance Policy** document, optimized across all three layers for accuracy and efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "## Design Choices & Experimentation Summary\n",
    "\n",
    "| Layer | Requirement | Design Choice Implemented | Rationale and Impact |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Embedding** | **Optimal Chunking** | **Custom Fixed-Size Character Splitter** (512 char, 128 overlap) | **Constraint Adherence & Simplicity:** Replaced dependency on `langchain-text-splitters` with a custom function using simple Python logic to meet the fixed-size chunking strategy mentioned in the requirements. |\n",
    "| **Embedding** | **Embedding Model** | `all-MiniLM-L6-v2` (`sentence-transformers`) | **Efficiency & Quality:** Selected for its excellent performance in semantic similarity tasks while remaining lightweight and fast for a practical RAG system. |\n",
    "| **Search** | **Mandatory Cache** | **Query-Based ChromaDB Cache** with `CACHE_THRESHOLD=0.05` | **Efficiency:** Reduces computation cost for redundant queries. The threshold ensures only highly similar queries trigger a cache hit, maintaining answer quality. |\n",
    "| **Search** | **Mandatory Re-ranker** | **Cross-Encoder Model:** `cross-encoder/ms-marco-MiniLM-L-6-v2` (`sentence-transformers.CrossEncoder`) | **Constraint Adherence & Quality of Search:** Used the `CrossEncoder` class from the **allowed `sentence-transformers` library** to refine the initial vector search results, guaranteeing the **Top 3** chunks are truly informative for the LLM. |\n",
    "| **Generation**| **Generation LLM** | **OpenAI's GPT-3.5-Turbo** | **Constraint Adherence:** Used the mandatory `openai` library for the generation layer, providing a high-quality model for synthesis. |\n",
    "| **Generation**| **Quality of Prompt** | **Exhaustive, Citation-driven Prompt** | **Trust & Verifiability:** The prompt strictly enforces answering *only* from the context and mandates **specific citations** (``), mitigating hallucination and ensuring factual accuracy. |\n",
    "\n",
    "---\n",
    "\n",
    "## Challenges Faced\n",
    "\n",
    "* **PDF Parsing:** Policy documents use complex formatting (tables, headers). This was solved by using **`pdfplumber`** with **custom logic** to extract and correctly integrate table data, preventing loss of critical information.\n",
    "* **LLM Hallucination:** Requiring **specific citations** in the final answer was the primary defense against the LLM generating plausible but incorrect information, ensuring the high factual accuracy required for insurance policy documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ipuDg7d8ZPu1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
